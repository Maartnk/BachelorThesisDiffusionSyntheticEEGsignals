{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U einops","metadata":{"id":"1lKbrA1ADX_t","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Diffusion model main code. Adjusted from Rogge and Rasul: https://github.com/huggingface/blog/blob/main/annotated-diffusion.md","metadata":{}},{"cell_type":"code","source":"import math\nfrom inspect import isfunction\nfrom functools import partial\n\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nfrom einops import rearrange\n\nimport torch\nfrom torch import nn, einsum\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nimport numpy as np\nfrom torch.optim import Adam\n\ndef exists(x):\n    return x is not None\n\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if isfunction(d) else d\n\nclass Residual(nn.Module):\n    def __init__(self, fn):\n        super().__init__()\n        self.fn = fn\n\n    def forward(self, x, *args, **kwargs):\n        return self.fn(x, *args, **kwargs) + x\n\ndef Upsample(dim):\n    return nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n\ndef Downsample(dim):\n    return nn.Conv1d(dim, dim, 4, 2, 1)\n\nclass SinusoidalPositionEmbeddings(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, time):\n        device = time.device\n        half_dim = self.dim // 2\n        embeddings = math.log(10000) / (half_dim - 1)\n        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n        embeddings = time[:, None] * embeddings[None, :]\n        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n        return embeddings\n\n\nclass Block(nn.Module):\n    def __init__(self, dim, dim_out, groups=8):\n        super().__init__()\n        self.proj = nn.Conv1d(dim, dim_out, 3, padding=1)\n        self.norm = nn.GroupNorm(groups, dim_out)\n        self.act = nn.SiLU()\n\n    def forward(self, x, scale_shift=None):\n        x = self.proj(x)\n        x = self.norm(x)\n\n        if exists(scale_shift):\n            scale, shift = scale_shift\n            x = x * (scale + 1) + shift\n\n        x = self.act(x)\n        return x\n\n\nclass ResnetBlock(nn.Module):\n    \"\"\"https://arxiv.org/abs/1512.03385\"\"\"\n\n    def __init__(self, dim, dim_out, *, time_emb_dim=None, groups=8):\n        super().__init__()\n        self.mlp = (\n            nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out))\n            if exists(time_emb_dim)\n            else None\n        )\n\n        self.block1 = Block(dim, dim_out, groups=groups)\n        self.block2 = Block(dim_out, dim_out, groups=groups)\n        self.res_conv = nn.Conv1d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n\n    def forward(self, x, time_emb=None):\n        h = self.block1(x)\n\n        if exists(self.mlp) and exists(time_emb):\n            time_emb = self.mlp(time_emb)\n            h = rearrange(time_emb, \"b c -> b c 1\") + h\n\n        h = self.block2(h)\n        return h + self.res_conv(x)\n\n\nclass ConvNextBlock(nn.Module):\n    \"\"\"https://arxiv.org/abs/2201.03545\"\"\"\n\n    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):\n        super().__init__()\n        self.mlp = (\n            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))\n            if exists(time_emb_dim)\n            else None\n        )\n\n        self.ds_conv = nn.Conv1d(dim, dim, 7, padding=3, groups=dim)\n\n        self.net = nn.Sequential(\n            nn.GroupNorm(1, dim) if norm else nn.Identity(),\n            nn.Conv1d(dim, dim_out * mult, 3, padding=1),\n            nn.GELU(),\n            nn.GroupNorm(1, dim_out * mult),\n            nn.Conv1d(dim_out * mult, dim_out, 3, padding=1),\n        )\n\n        self.res_conv = nn.Conv1d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n\n    def forward(self, x, time_emb=None):\n        h = self.ds_conv(x)\n\n        if exists(self.mlp) and exists(time_emb):\n            assert exists(time_emb),\n            condition = self.mlp(time_emb)\n            h = h + rearrange(condition, \"b c -> b c 1\")\n\n        h = self.net(h)\n        return h + self.res_conv(x)\n\nclass Attention(nn.Module):\n    def __init__(self, dim, heads=4, dim_head=32):\n        super().__init__()\n        self.scale = dim_head**-0.5\n        self.heads = heads\n        hidden_dim = dim_head * heads\n        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)\n        self.to_out = nn.Conv1d(hidden_dim, dim, 1)\n\n    def forward(self, x):\n        b, c, h = x.shape\n        qkv = self.to_qkv(x).chunk(3, dim=1)\n        q, k, v = map(\n            lambda t: rearrange(t, \"b (h c) x -> b h c (x)\", h=self.heads), qkv\n        )\n        q = q * self.scale\n\n        sim = einsum(\"b h d i, b h d j -> b h i j\", q, k)\n        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n        attn = sim.softmax(dim=-1)\n\n        out = einsum(\"b h i j, b h d j -> b h i d\", attn, v)\n        out = rearrange(out, \"b h (x) d -> b (h d) x\", x=h)\n        return self.to_out(out)\n\nclass LinearAttention(nn.Module):\n    def __init__(self, dim, heads=4, dim_head=32):\n        super().__init__()\n        self.scale = dim_head**-0.5\n        self.heads = heads\n        hidden_dim = dim_head * heads\n        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias=False)\n\n        self.to_out = nn.Sequential(nn.Conv1d(hidden_dim, dim, 1),\n                                    nn.GroupNorm(1, dim))\n\n    def forward(self, x):\n        b, c, h = x.shape\n        qkv = self.to_qkv(x).chunk(3, dim=1)\n        q, k, v = map(\n            lambda t: rearrange(t, \"b (h c) x -> b h c (x)\", h=self.heads), qkv\n        )\n\n        q = q.softmax(dim=-2)\n        k = k.softmax(dim=-1)\n\n        q = q * self.scale\n        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n\n        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n        out = rearrange(out, \"b h c (x) -> b (h c) x\", h=self.heads, x=h)\n        return self.to_out(out)\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        self.fn = fn\n        self.norm = nn.GroupNorm(1, dim)\n\n    def forward(self, x):\n        x = self.norm(x)\n        return self.fn(x)\n\n\nclass Unet(nn.Module):\n    def __init__(\n            self,\n            dim,\n            init_dim=None,\n            out_dim=None,\n            dim_mults=(1, 2, 4, 8),\n            channels=3,\n            with_time_emb=True,\n            resnet_block_groups=8,\n            use_convnext=True,\n            convnext_mult=2,\n    ):\n        super().__init__()\n\n        self.channels = channels\n\n        init_dim = default(init_dim, dim // 3 * 2)\n        self.init_conv = nn.Conv1d(channels, init_dim, 7, padding=3)\n\n        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n        in_out = list(zip(dims[:-1], dims[1:]))\n\n        if use_convnext:\n            block_klass = partial(ConvNextBlock, mult=convnext_mult)\n        else:\n            block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n\n        #time embeddings\n        if with_time_emb:\n            time_dim = dim * 4\n            self.time_mlp = nn.Sequential(\n                SinusoidalPositionEmbeddings(dim),\n                nn.Linear(dim, time_dim),\n                nn.GELU(),\n                nn.Linear(time_dim, time_dim),\n            )\n        else:\n            time_dim = None\n            self.time_mlp = None\n\n        #layers\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n        num_resolutions = len(in_out)\n\n        for ind, (dim_in, dim_out) in enumerate(in_out):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.downs.append(\n                nn.ModuleList(\n                    [\n                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),\n                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n                        Downsample(dim_out) if not is_last else nn.Identity(),\n                    ]\n                )\n            )\n\n        mid_dim = dims[-1]\n        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n\n        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.ups.append(\n                nn.ModuleList(\n                    [\n                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n                        Upsample(dim_in) if not is_last else nn.Identity(),\n                    ]\n                )\n            )\n\n        out_dim = default(out_dim, channels)\n        self.final_conv = nn.Sequential(\n            block_klass(dim, dim), nn.Conv1d(dim, out_dim, 1)\n        )\n\n    def forward(self, x, time):\n        x = self.init_conv(x)\n\n        t = self.time_mlp(time) if exists(self.time_mlp) else None\n\n        h = []\n\n        #downsampling\n        for block1, block2, attn, downsample in self.downs:\n            x = block1(x, t)\n            x = block2(x, t)\n            x = attn(x)\n            h.append(x)\n            x = downsample(x)\n\n        # the bottleneck\n        x = self.mid_block1(x, t)\n        x = self.mid_attn(x)\n        x = self.mid_block2(x, t)\n\n        #upsampling\n        for block1, block2, attn, upsample in self.ups:\n            x = torch.cat((x, h.pop()), dim=1)\n            x = block1(x, t)\n            x = block2(x, t)\n            x = attn(x)\n            x = upsample(x)\n\n        return self.final_conv(x)\n\ndef cosine_beta_schedule(timesteps, s=0.008):\n    \"\"\"\n    cosine schedule as proposed in https://arxiv.org/abs/2102.09672\n    \"\"\"\n    steps = timesteps + 1\n    x = torch.linspace(0, timesteps, steps)\n    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n    return torch.clip(betas, 0.0001, 0.9999)\n\ndef linear_beta_schedule(timesteps):\n    beta_start = 0.0001\n    beta_end = 0.02\n    return torch.linspace(beta_start, beta_end, timesteps)\n\ndef quadratic_beta_schedule(timesteps):\n    beta_start = 0.0001\n    beta_end = 0.02\n    return torch.linspace(beta_start**0.5, beta_end**0.5, timesteps) ** 2\n\ndef sigmoid_beta_schedule(timesteps):\n    beta_start = 0.0001\n    beta_end = 0.02\n    betas = torch.linspace(-6, 6, timesteps)\n    return torch.sigmoid(betas) * (beta_end - beta_start) + beta_start\n\ntimesteps = 5000\n\nbetas = linear_beta_schedule(timesteps=timesteps)\n\nalphas = 1. - betas\nalphas_cumprod = torch.cumprod(alphas, axis=0)\nalphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\nsqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n\nsqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\nsqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n\nposterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n\ndef extract(a, t, x_shape):\n    batch_size = t.shape[0]\n    out = a.gather(-1, t.cpu())\n    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n\ndef q_sample(x_start, t, noise=None):\n    if noise is None:\n        noise = torch.randn_like(x_start)\n\n    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n    sqrt_one_minus_alphas_cumprod_t = extract(\n        sqrt_one_minus_alphas_cumprod, t, x_start.shape\n    )\n\n    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n\ndef get_noisy_image(x_start, t):\n  x_noisy = q_sample(x_start, t=t)\n  return x_noisy\n\ndef p_losses(denoise_model, x_start, t, noise=None, loss_type=\"l1\"):\n    if noise is None:\n        noise = torch.randn_like(x_start)\n\n    x_noisy = q_sample(x_start=x_start, t=t, noise=noise)\n    predicted_noise = denoise_model(x_noisy, t)\n\n    if loss_type == 'l1':\n        loss = F.l1_loss(noise, predicted_noise)\n    elif loss_type == 'l2':\n        loss = F.mse_loss(noise, predicted_noise)\n    elif loss_type == \"huber\":\n        loss = F.smooth_l1_loss(noise, predicted_noise)\n    else:\n        raise NotImplementedError()\n\n    return loss\n\ndef dataloader(x, batch_size):\n    return DataLoader(x, batch_size)\n\n\n@torch.no_grad()\ndef p_sample(model, x, t, t_index):\n    betas_t = extract(betas, t, x.shape)\n    sqrt_one_minus_alphas_cumprod_t = extract(\n        sqrt_one_minus_alphas_cumprod, t, x.shape\n    )\n    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n\n    model_mean = sqrt_recip_alphas_t * (\n            x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n    )\n\n    if t_index == 0:\n        return model_mean\n    else:\n        posterior_variance_t = extract(posterior_variance, t, x.shape)\n        noise = torch.randn_like(x)\n        return model_mean + torch.sqrt(posterior_variance_t) * noise\n\n@torch.no_grad()\ndef p_sample_loop(model, shape):\n    device = next(model.parameters()).device\n\n    b = shape[0]\n    img = torch.randn(shape, device=device)\n    imgs = []\n\n    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)\n        imgs.append(img.cpu().numpy())\n    return imgs\n\n\n@torch.no_grad()\ndef sample(model, data_size = 1024, batch_size=16, channels=2):\n    return p_sample_loop(model, shape=(batch_size, channels, data_size))","metadata":{"id":"gx30kbfkCQO-","execution":{"iopub.status.busy":"2022-12-13T12:55:24.328956Z","iopub.execute_input":"2022-12-13T12:55:24.329390Z","iopub.status.idle":"2022-12-13T12:55:26.167098Z","shell.execute_reply.started":"2022-12-13T12:55:24.329332Z","shell.execute_reply":"2022-12-13T12:55:26.166243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import dataset and transform it","metadata":{}},{"cell_type":"code","source":"dataimport = np.load('/kaggle/input/eegdata/EEG_all_epochs.npy')\ntransformeddata = []\nfor i in dataimport:\n  datanorm = (i-i.min())/(i.max()-i.min())\n  transformeddata.append(datanorm)\ntransformeddata = np.asarray(transformeddata)\ntotaltransformeddata = torch.from_numpy(transformeddata)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:55:36.609884Z","iopub.execute_input":"2022-12-13T12:55:36.611393Z","iopub.status.idle":"2022-12-13T12:55:37.099734Z","shell.execute_reply.started":"2022-12-13T12:55:36.611321Z","shell.execute_reply":"2022-12-13T12:55:37.098542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_size = 512\nchannels = 1\nbatch_size = 61\n\ndl = DataLoader(totaltransformeddata, batch_size = batch_size)\nbatch = next(iter(dl))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:06:02.326993Z","iopub.execute_input":"2022-12-11T12:06:02.327353Z","iopub.status.idle":"2022-12-11T12:06:02.337814Z","shell.execute_reply.started":"2022-12-11T12:06:02.327316Z","shell.execute_reply":"2022-12-11T12:06:02.336893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initialize architecture","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = Unet(\n  dim=data_size,\n  channels=channels,\n  dim_mults=(1,2,4)\n)\nmodel.to(device)\n\noptimizer = Adam(model.parameters(), lr=1e-3)","metadata":{"id":"I7keHOsxvGtr","execution":{"iopub.status.busy":"2022-12-11T12:06:05.094557Z","iopub.execute_input":"2022-12-11T12:06:05.094925Z","iopub.status.idle":"2022-12-11T12:06:11.357896Z","shell.execute_reply.started":"2022-12-11T12:06:05.094894Z","shell.execute_reply":"2022-12-11T12:06:11.356870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train model","metadata":{}},{"cell_type":"code","source":"epochs = 100\n\nfor epoch in range(epochs):\n    print('Start of epoch', epoch)\n    for step, batch in enumerate(dl):\n        optimizer.zero_grad()\n\n        batch_size = batch.shape[0]\n        batch = batch.to(device = device, dtype=torch.float)\n\n        t = torch.randint(0, timesteps, (batch_size,), device=device).long()\n\n        loss = p_losses(model, torch.unsqueeze(batch, dim=1), t, loss_type=\"huber\")\n\n        if step % 25 == 0:\n          print(\"Loss:\", loss.item())\n\n        loss.backward()\n        optimizer.step()\n    print('Epoch', epoch, 'completed')","metadata":{"id":"84TRyfufvJIC","outputId":"52d7b8f1-db31-4ef9-84f4-cd2f7593a08a","execution":{"iopub.status.busy":"2022-12-06T23:02:28.551891Z","iopub.execute_input":"2022-12-06T23:02:28.552249Z","iopub.status.idle":"2022-12-06T23:05:52.648569Z","shell.execute_reply.started":"2022-12-06T23:02:28.552218Z","shell.execute_reply":"2022-12-06T23:05:52.647660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save model","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'ModelE100T5kSCLIN.pth')","metadata":{"execution":{"iopub.status.busy":"2022-12-05T18:51:04.570903Z","iopub.execute_input":"2022-12-05T18:51:04.571310Z","iopub.status.idle":"2022-12-05T18:51:07.446298Z","shell.execute_reply.started":"2022-12-05T18:51:04.571277Z","shell.execute_reply":"2022-12-05T18:51:07.445358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate samples from trained model","metadata":{}},{"cell_type":"code","source":"samples = sample(model, data_size = 512, batch_size=4, channels=channels)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T12:06:27.571396Z","iopub.execute_input":"2022-12-11T12:06:27.571771Z","iopub.status.idle":"2022-12-11T13:23:35.659441Z","shell.execute_reply.started":"2022-12-11T12:06:27.571742Z","shell.execute_reply":"2022-12-11T13:23:35.658536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('Samples.npy', samples)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T13:23:39.857970Z","iopub.execute_input":"2022-12-11T13:23:39.858328Z","iopub.status.idle":"2022-12-11T13:23:40.932173Z","shell.execute_reply.started":"2022-12-11T13:23:39.858290Z","shell.execute_reply":"2022-12-11T13:23:40.930572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot generated samples","metadata":{}},{"cell_type":"code","source":"sampledsteps = [0,1250,2500,3750,4999]\nfor b in range(5):\n  for i in sampledsteps:\n    generated = samples[i][b]\n    generated2 = np.vstack((np.arange(1, 513), generated))\n    plt.scatter(generated2[0], generated2[1])\n    plt.show()\n    plt.plot(generated2[0], generated2[1])\n    plt.show()","metadata":{"id":"izqS7FdgSTTy","execution":{"iopub.status.busy":"2022-12-06T23:09:11.602034Z","iopub.execute_input":"2022-12-06T23:09:11.602420Z","iopub.status.idle":"2022-12-06T23:09:16.917957Z","shell.execute_reply.started":"2022-12-06T23:09:11.602383Z","shell.execute_reply":"2022-12-06T23:09:16.916955Z"},"trusted":true},"execution_count":null,"outputs":[]}]}